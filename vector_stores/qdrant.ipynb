{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://python.langchain.com/en/latest/modules/indexes/vectorstores/examples/qdrant.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import qdrant_client\n",
    "import sys\n",
    "sys.path.insert(0, '../')\n",
    "import local_secrets as secrets\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores import Qdrant\n",
    "from langchain.vectorstores import Pinecone\n",
    "from langchain.document_loaders import TextLoader\n",
    "from llama_index.readers.qdrant import QdrantReader\n",
    "from llama_index import GPTListIndex\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import clear_output\n",
    "import pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.environ['OPENAI_API_KEY'] = secrets.techstyle_openai_key\n",
    "os.environ['PINECONE_API_KEY'] = secrets.techstyle_pinecone_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "loader = TextLoader('../state_of_the_union.txt')\n",
    "documents = loader.load()\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "docs = text_splitter.split_documents(documents)\n",
    "embeddings = OpenAIEmbeddings()\n",
    "qdrant = Qdrant.from_documents(docs, embeddings, url='http://localhost:6333', collection_name=\"state_of_the_union\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "reader = QdrantReader(host=\"localhost\")\n",
    "query_vector=[0.3, 0.7]*768\n",
    "documents = reader.load_data(collection_name=\"github_llama_index\", query_vector=query_vector, limit=5)\n",
    "index = GPTListIndex.from_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'file_name': 'mock_embed_model.py',\n",
       "  'file_path': 'llama_index/token_counter/mock_embed_model.py'},\n",
       " {'file_name': 'sql_query.py',\n",
       "  'file_path': 'llama_index/indices/struct_store/sql_query.py'},\n",
       " {'file_name': 'base.py',\n",
       "  'file_path': 'llama_index/indices/struct_store/base.py'},\n",
       " {'file_name': 'pandas_query.py',\n",
       "  'file_path': 'llama_index/indices/struct_store/pandas_query.py'},\n",
       " {'file_name': 'schema.py',\n",
       "  'file_path': 'llama_index/indices/query/schema.py'}]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[doc.extra_info for doc in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1536"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents[0].get_embedding())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# https://qdrant.tech/articles/langchain-integration/\n",
    "os.environ['OPENAI_API_KEY'] = secrets.techstyle_openai_key\n",
    "llm = ChatOpenAI()\n",
    "\n",
    "# qdrant\n",
    "#client = qdrant_client.QdrantClient(url='http://localhost:6333')\n",
    "#retriever = Qdrant(client=client, collection_name='github_llama_index', embeddings=OpenAIEmbeddings(), content_payload_key='text').as_retriever(search_kwargs={\"k\": 4})\n",
    "\n",
    "# pinecone\n",
    "client = pinecone.init(api_key=secrets.techstyle_pinecone_api_key, environment='us-east-1-aws')\n",
    "retriever = Pinecone(index=pinecone.Index('ssk'), embedding_function=OpenAIEmbeddings, text_key='text').as_retriever()\n",
    "\n",
    "chain = load_qa_chain(llm=llm, chain_type='stuff') \n",
    "\n",
    "question = 'What are the classes in the llama_index package?'\n",
    "question = 'How is the llama_index Node class used'\n",
    "question = 'Show an example of how to use the llama_index Node class'\n",
    "question = 'How can several llama_indexes be composed?'\n",
    "question = 'Explain llama_index nodes'\n",
    "\n",
    "# documents = retriever.get_relevant_documents(question)\n",
    "#chain.run(input_documents=documents, question=question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ceaa99ebebc544669bc69913d6b08764",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Text(value=''), Button(description='Chat', style=ButtonStyle()), Output()))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def on_button_clicked(b):\n",
    "    with output:\n",
    "        clear_output()\n",
    "        documents = retriever.get_relevant_documents(question.value)\n",
    "        print(chain.run(input_documents=documents, question=question.value))\n",
    "output = widgets.Output()\n",
    "question = widgets.Text()\n",
    "button = widgets.Button(description='Chat')\n",
    "button.on_click(on_button_clicked)\n",
    "widgets.VBox([question, button, output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['page_content'], output_parser=None, partial_variables={}, template='{page_content}', template_format='f-string', validate_template=True)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.document_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Pinecone.__init__() got an unexpected keyword argument 'text_field'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m retriever \u001b[38;5;241m=\u001b[39m \u001b[43mPinecone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpinecone\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mIndex\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mssk\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_function\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mOpenAIEmbeddings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_field\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mas_retriever()\n\u001b[1;32m      2\u001b[0m qa \u001b[38;5;241m=\u001b[39m RetrievalQA\u001b[38;5;241m.\u001b[39mfrom_chain_type(llm\u001b[38;5;241m=\u001b[39mllm, chain_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstuff\u001b[39m\u001b[38;5;124m\"\u001b[39m, retriever\u001b[38;5;241m=\u001b[39mretriever, return_source_documents\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      3\u001b[0m result \u001b[38;5;241m=\u001b[39m qa({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHow can several llama_indexes be composed? Show an example.\u001b[39m\u001b[38;5;124m'\u001b[39m})\n",
      "\u001b[0;31mTypeError\u001b[0m: Pinecone.__init__() got an unexpected keyword argument 'text_field'"
     ]
    }
   ],
   "source": [
    "retriever = Pinecone(index=pinecone.Index('ssk'), embedding_function=OpenAIEmbeddings.embed_query, text_key='text').as_retriever()\n",
    "qa = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=retriever, return_source_documents=True)\n",
    "result = qa({\"query\": 'How can several llama_indexes be composed? Show an example.'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = Qdrant(client=client, collection_name='github_llama_index', embeddings=OpenAIEmbeddings(), content_payload_key='text').as_retriever()\n",
    "qa = RetrievalQA.from_chain_type(llm=llm, chain_type=\"map_reduce\", retriever=retriever, return_source_documents=True)\n",
    "result = qa({\"query\": 'How can several llama_indexes be composed? Show an example.'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dimension': 1536,\n",
      " 'index_fullness': 0.0,\n",
      " 'namespaces': {'': {'vector_count': 335}},\n",
      " 'total_vector_count': 335}\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "OpenAIEmbeddings.embed_query() missing 1 required positional argument: 'text'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(index\u001b[38;5;241m.\u001b[39mdescribe_index_stats())\n\u001b[1;32m      3\u001b[0m vectorstore \u001b[38;5;241m=\u001b[39m Pinecone(index\u001b[38;5;241m=\u001b[39mindex, embedding_function\u001b[38;5;241m=\u001b[39mOpenAIEmbeddings\u001b[38;5;241m.\u001b[39membed_query, text_key\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m documents \u001b[38;5;241m=\u001b[39m \u001b[43mvectorstore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msimilarity_search\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mHow can several llama_indexes be composed?\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/langchain_play/lib/python3.10/site-packages/langchain/vectorstores/pinecone.py:155\u001b[0m, in \u001b[0;36mPinecone.similarity_search\u001b[0;34m(self, query, k, filter, namespace, **kwargs)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msimilarity_search\u001b[39m(\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    138\u001b[0m     query: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    143\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[Document]:\n\u001b[1;32m    144\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return pinecone documents most similar to query.\u001b[39;00m\n\u001b[1;32m    145\u001b[0m \n\u001b[1;32m    146\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;124;03m        List of Documents most similar to the query and score for each\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 155\u001b[0m     docs_and_scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msimilarity_search_with_score\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnamespace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnamespace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [doc \u001b[38;5;28;01mfor\u001b[39;00m doc, _ \u001b[38;5;129;01min\u001b[39;00m docs_and_scores]\n",
      "File \u001b[0;32m~/anaconda3/envs/langchain_play/lib/python3.10/site-packages/langchain/vectorstores/pinecone.py:115\u001b[0m, in \u001b[0;36mPinecone.similarity_search_with_score\u001b[0;34m(self, query, k, filter, namespace)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m namespace \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    114\u001b[0m     namespace \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_namespace\n\u001b[0;32m--> 115\u001b[0m query_obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_embedding_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    116\u001b[0m docs \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    117\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index\u001b[38;5;241m.\u001b[39mquery(\n\u001b[1;32m    118\u001b[0m     [query_obj],\n\u001b[1;32m    119\u001b[0m     top_k\u001b[38;5;241m=\u001b[39mk,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[38;5;28mfilter\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mfilter\u001b[39m,\n\u001b[1;32m    123\u001b[0m )\n",
      "\u001b[0;31mTypeError\u001b[0m: OpenAIEmbeddings.embed_query() missing 1 required positional argument: 'text'"
     ]
    }
   ],
   "source": [
    "index = pinecone.Index('ssk')\n",
    "print(index.describe_index_stats())\n",
    "vectorstore = Pinecone(index=index, embedding_function=OpenAIEmbeddings.embed_query, text_key='text')\n",
    "documents = vectorstore.similarity_search('How can several llama_indexes be composed?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0.171\n"
     ]
    }
   ],
   "source": [
    "import langchain\n",
    "print(langchain.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Configuration' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[52], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfiguration\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'Configuration' object is not callable"
     ]
    }
   ],
   "source": [
    "index.configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
